[LinkedIn](https://www.linkedin.com/posts/byeongheon-lee-2b83aa222_critique-fine-tuning-%EB%B0%B0%EC%9A%B0%EA%B3%A0-%EC%8B%B6%EC%9C%BC%EB%A9%B4-%EB%B9%84%ED%8C%90%ED%95%98%EB%9D%BC-%EC%B5%9C%EA%B7%BC-supervised-activity-7303617597923581952-yydw?utm_source=share&utm_medium=member_desktop&rcm=ACoAADfxcywBkH2Mi2-YPZm7jSZERa3dQ2_DDEY)

연구: https://arxiv.org/pdf/2501.17703v2  
연구 소개 사이트(데이터셋과 모델 공개): https://tiger-ai-lab.github.io/CritiqueFineTuning/  
저자 설명 트위터: https://x.com/WenhuChen/status/1885060597500567562  

Critique Fine-Tuning: 배우고 싶으면 비판하라

최근 Supervised Fine-Tuning(SFT)의 효율을 높이기 위한 새로운 방식이 제안됐습니다. 질문에 '답'을 직접 생성하는 방식 대신, 이미 생성된 '답을 비판적으로 평가'하는 방식을 통해 적은 데이터로도 모델의 성능을 크게 향상시키는 연구입니다. 아이디어가 간단한데 제시한 성능은 괜찮은 거 같아서 공유합니다.

 핵심 아이디어
 
 - Llama3나 Mistral까지는 SFT가 효과적이었지만, 데이터의 양과 퀄리티를 높여도 SFT로 인한 개선폭이 둔화되는 것이 목격되었습니다.
 - 연구진은 인간이 학습할 때 단순히 정답을 외우는 것이 아니라 틀린 답을 분석하며 배우는 방식에서 착안했습니다.
- 기존의 SFT가 정답을 모방하는 데 초점을 맞추는 것과 달리, Critique Fine-Tuning(CFT)은 질문과 이미 생성된 답변을 입력 받아 상세한 평가 및 피드백을 생성하도록 학습시킵니다.


---

 데이터 구축 및 학습 과정

- 주로 사용된 WebInstruct는 온라인 교육 및 퀴즈 사이트에서 수집된 수학/STEM 분야의 질문들을 포함하고 있습니다. 여기서 50K 정도 추출합니다. 
- 그 뒤 Qwen-72B, Mixtral 등이 생성한 답변을 실험 조건에 따라 달리 사용합니다. 기존의 SFT와 달리 답변이 정답이 아니어도 되며, 50% 이상이 잘못된 답변으로 구성되어도 '노이즈'가 포함된 채로 사용합니다. 
- 이를 보완하기 위해 GPT-4o 등의 모델로 원본 답변을 검증하고 비판하는 피드백을 추가하는 방식으로 CFT 데이터셋을 구성했습니다. 
- 학습에 사용된 모델은 DeepSeek-Math-7B, Qwen2.5-7B, Qwen2.5-Math-7B 입니다. SFT와 CFT를 비교하기 위해 base 모델만을 사용했습니다.
- CFT의 성능이 데이터셋에 따라 달라지는 지 판단하기 위해 MetaMathQA와 NuminaMath 등의 데이터셋을 추가로 실험했고, 벤치마크도 MATH, GSM8K, OlympiadBench, GPQA 등 다양하게 검증했습니다.

---

벤치마크 점수와 자원 효율성 개선

- CFT는 SFT 대비 4~10%의 일관된 성능 향상을 보였으며, 수학과 STEM 분야의 여러 벤치마크에서 우수한 성적을 거뒀습니다.
- 데이터 효율성 측면에서 매우 뛰어난데, 특히 CFT를 통해 소량의 데이터로도 기존에 수백만 개의 데이터를 사용해 SFT를 적용한 모델과 비슷하거나 더 뛰어난 성능을 보였습니다(Qwen2.5-Math-7B-CFT with 50K vs Qwen2.5-Math-7B-Instruct with 2M).
- 특히, 기존 강화학습(RL) 기반 방법과 비교해도 학습 효율이 크게 개선됨을 보였는데,
    - CFT 방식으로 H100 GPU 한 대를 8시간 학습한 모델이
    - RL 방식으로 H100 32대를 36시간 학습한 모델과 유사한 벤치마크 점수를 기록했습니다.
    - 단순 계산으로 보면 약 140배의 학습 효율 개선을 달성한 셈입니다.
- 일반적인 SFT는 이미 reasoning corpus로 학습된 모델들의 성능을 오히려 낮추는 것으로 드러났습니다. 

---

일반화 성능과 한계

- 학습 곡선을 보면 CFT 방식이 기존 SFT보다 빠르게 수렴하며, 초기부터 높은 정확도를 유지하는 경향이 있습니다.
- 연구진은 다양한 데이터 소스(WebInstruct, MetaMathQA, NuminaMath 등)에서도 동일한 실험을 진행했고, CFT가 일관되게 기존 SFT보다 성능을 개선한다는 결과를 확인했습니다. 
- 비판을 생성하는 ‘교사’ 모델(GPT-4o vs GPT-4o-mini)의 품질이 성능에 영향을 미치지만, 비교적 작은 모델을 사용해도 충분한 효과를 얻을 수 있음을 보여줍니다.
- 연구진은 모델이 스스로 자신의 답변을 평가하는 자기 비판(self-critique) 방법도 시도했지만,
    - 평가 기준이 일정하지 않고
    - 추론 과정에서 불안정성이 증가하며
    - 결과적으로 직접 추론하는 방식보다 성능이 낮아지는 문제가 발생했습니다.

---

마무리

- GPT 4o같은 모델들이 생성한 데이터를 사용했으니, 이것도 결국에는 증류에 더 가까워 보이는데 연구 내에서는 그런 언급은 없었습니다.
- 사용된 데이터셋이나 하드웨어 자원들이 압도적으로 적어서, 이 결과가 재현될 수 있을지 의문이 들기는 합니다. 데이터셋에서만 40배, gpu도 140배 가량 적게 쓰고도 벤치마크 점수는 같다고 하니까요.
- 저자 트위터에 다른 사람이 남긴 글을 보니 Llama3.1에서는 그만큼의 성능 향상이 보이지 않았다고 하는데, 추후 연구를 지켜봐야 될 것 같습니다.
- 또한 데이터셋을 ~100K까지 늘리면 성능이 개선되지만 그 이후로는 포화된다고 합니다.
- 저자들이 처음에는 벤치마크 점수만 공개하고 SFT/CFT 모델들의 답변 비교 case study를 안 넣었더니 바로 트위터에서 피드백이 와서 추가했더라구요. 개별 예시를 제시하는 것이 확실히 더 직관적인 것 같습니다. 다만 이 연구의 답변들은 눈에 띄는 차이점은 없는 거 같네요. 
- RL 말고 긴 reasoning을 위해서 다른 접근 방식이 많이 나오기는 하네요. 그리고 그 효과는 대부분 '길고 일관된 데이터셋'에서 나오는 것 같습니다. 허깅페이스에 공개한 CFT 데이터셋을 훑어봤을 때 질문에 대한 답변보다 피드백이 2배 이상 긴 경우가 많았습니다. '비판'하는 데이터가 효과가 있을 수는 있겠지만, 저는 길이와 일관성이 더 중요해 보이네요.
- 과연 학습 데이터의 길이와 파라미터의 수를 늘리는 것으로 끝없는 재귀 개선을 할 수 있을지, 다시 한 번 LLM이 '창발성'을 보여줄 지 기대가 됩니다. 이제는 인터넷의 데이터를 굳이 가져가서 학습에 쓰는 것은 외부와의 마찰만 유발하고, SOTA 모델들의 학습에도 크게 도움이 되지 않을 것 같습니다. 전문가 여럿이서 책을 작성하거나, 제한된 공간에서  토론을 하는 것 정도가 가장 이상적일 거 같은데, 데이터 생성에 드는 돈이 하드웨어에 드는 돈 만큼 들겠다는 생각이 드네요.