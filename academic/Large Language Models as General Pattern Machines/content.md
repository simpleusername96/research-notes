2024.06.15

[LinkedIn](https://medium.com/@simple0314/llm%EC%9D%80-%ED%8C%A8%ED%84%B4%EC%9D%84-%EC%9D%BD%EB%8A%94%EB%8B%A4-7a52e7fde34e)

Large Language Models as General Pattern Machines
https://arxiv.org/abs/2307.04721

tl;dr
LLM은 자연어 외에도 이미지, 로봇 제어 데이터 등 다양한 형식의 패턴을 인식하고 처리할 수 있음
연구진은 LLM의 패턴 인식 능력을 ARC 벤치마크, 수학 함수/로봇 동작 완성, 경로 탐색/로봇 제어 최적화  문제에 대해 시험 
문제가 자연어가 아닌 형태로 제시되어도 토큰 간 관계를 파악해 높은 수준의 문제 해결 능력을 보임
연구 결과는 LLM이 로보틱스 분야에서 활용될 가능성을 제시하지만, 실제 적용에는 한계가 있음
메모: LLM의 패턴 인식 능력을 극대화하는 과정에서 Chain-of-Thought, XML 태그 활용 등의 프롬프트 기법이 알려진 것이 아닌가 추측

1. 서론
LLM(Large Language Model, 대규모 언어 모델)은 다양한 자연어 데이터를 학습하며 일종의 패턴을 발견해 추론, 논리, 수학 등의 영역에서 뛰어난 성능을 보여주고 있음
LLM이 자연어 이외의 데이터 형식에 대해서도 패턴 인식 및 처리 능력을 가지고 있다는 것이 이 연구의 주요 가설
즉, LLM을 자연어라는 특정 영역을 넘어서 다양한 형식의 시퀀스 데이터(예: 이미지의 픽셀값, 로봇 관절의 위치 등)를 처리할 수 있음
이를 바탕으로 로보틱스 분야에서 제어, 계획, 최적화 등의 문제를 해결하는데 활용될 수 있다는 것이 이 연구의 핵심 아이디어

1. 기존 연구와의 차이점
기존 연구는 주로 LLM을 자연어로 주어지는 instruction을 따르거나(robot instruction following), 보상함수를 설계하는 등 추상적이고 고차원적인 작업에 활용
 - 예: "Bring me a cup of water"라는 instruction이 주어지면, LLM이 이를 로봇의 low-level 동작으로 변환
반면 이 연구는 로봇 동작 자체를 나타내는 trajectory나 dynamics 데이터를 직접 모델링하는 low-level에서의 활용 가능성을 탐색
 - 예: 로봇 관절의 시계열 데이터 (theta1, theta2, …, theta_n)이 입력으로 주어지면, 다음 timestep의 관절 값을 예측

1. LLM의 패턴 인식 및 활용 가능성 분석
3.1 Sequence Transformation
주어진 입력 시퀀스를 특정 규칙에 따라 변환하여 새로운 출력 시퀀스를 만들어내는 작업 평가 
ARC(Abstraction and Reasoning Corpus) 벤치마크 활용
ARC는 다양한 기하학적 패턴의 변환 작업들로 구성 (예: 그림에서 특정 도형의 색깔을 바꾸기)
저자들은 입력 시퀀스를 구성하는 방법에 따라 LLM의 성능이 영향을 받을 수 있음을 발견 
 - 인접한 숫자 토큰들을 하나의 토큰으로 묶어서 임베딩하면(예: "3 4" → "34") 패턴 인식이 어려워짐 
 - 특정 Byte-Pair Encoding tokenizer들은 숫자를 나눠서 인식하지 않고 합쳐서 인식하기 때문(예: "86"을 "8"과 "6"이 아닌 "86"으로 인식)
 - "8686, 6868; 7979,"와 같은 경우 위와 같은 이유로 패턴을 인식하지 못하게 됨
 - 이는 토큰 단위가 시퀀스에 내재된 패턴과 일치해야 함을 시사
또한, ARC 문제의 입출력 데이터를 숫자(0–9)가 아닌 완전히 다른 임의의 토큰(단어)로 치환하여도 여전히 문제 해결이 가능했음
 - 예를 들어 "8686 ⇒ 6868 / 7979 ⇒ " 와 같은 패턴 문제를 "falls +# falls +# ⇒ +# falls +# falls / UI Chev UI Chev ⇒ " 로 바꾸어도 정답인 "Chev UI Chev UI"를 맞출 수 있었음
 - 이는 LLM이 개별 토큰의 의미보다는 토큰들의 상대적 배치 관계 자체에 주목하여 패턴을 인식할 수 있음을 의미 
즉, LLM이 개별 토큰의 구체적인 의미와는 무관하게, 보다 일반적인 수준에서 추상적인 패턴을 인식하고 외삽할 수 있는 능력을 보유하고 있음을 시사
이는 LLM의 패턴 인식이 단순히 개별 토큰 간의 의미적 연관성을 파악하는 것이 아니라, 토큰 간의 구조적/통계적 관계성을 학습하는 데에서 기인한다고 볼 수 있음
그 결과 LLM들은 별도의 fine-tuning 없이도 입력-출력 예제만으로 제법 많은 수의 ARC 문제들을 풀 수 있었으나, 전반적인 성능은 여전히 사람에 크게 못 미치는 수준

저자들은 이를 개선하기 위해 문제 난이도를 조절할 수 있는 새로운 벤치마크인 PCFG(Probabilistic Context-Free Grammar) 데이터셋을 제안
PCFG는 다양한 기하학적 변환 규칙들(회전, 반전, 복사 등)을 조합하여 무작위로 문제를 생성
 - 변환 규칙의 개수(w)와 시퀀스의 길이(k)를 조절함으로써 난이도 조정 가능
PCFG에서는 LLM의 크기에 비례하여 성능이 향상되는 경향을 관찰
 - 단, 여전히 규칙이 복잡해지고(w↑) 시퀀스가 길어질수록(k↑) 급격히 성능이 떨어짐

3.2 Sequence Completion
저자들은 사인 함수와 같은 간단한 수학 함수부터 로봇 관절의 시계열 데이터에 이르기까지 다양한 종류의 시퀀스에 대해 LLM의 외삽 능력을 평가
실험 결과, LLM은 입력으로 주어진 시퀀스의 일부만 관찰하고도 나머지 부분을 상당히 정확하게 예측할 수 있었음
 - 특히 주목할 점은 이러한 외삽 능력이 입력 프롬프트에 제공되는 context의 양에 비례하여 향상된다는 사실
 - 또한 동일한 context에 대해서도 모델의 크기가 클수록 더 나은 성능을 보임

보다 실용적인 활용 가능성을 타진하기 위해 저자들은 로봇을 이용한 실험도 진행
 - 사람이 로봇 팔을 직접 조작하여 책상 위를 쓸어내는 행동을 시연
 - 시연의 앞부분 2/3 정도를 LLM에게 입력으로 제공하고, 나머지 1/3에 해당하는 동작을 예측하도록 함
 - 그 결과 로봇은 사람의 행동 패턴을 잘 모사하여 쓸어내기 동작을 완료할 수 있었음
이와 유사하게 화이트보드에 글씨를 쓰는 행동 패턴도 LLM을 통해 외삽 가능함을 확인
이러한 실험들은 LLM이 모터 제어 신호를 직접 출력하지는 못하더라도, high-level에서의 행동 계획에는 활용될 수 있음을 시사

3.3 Sequence Improvement
저자들은 transformation과 completion의 시너지를 통해 LLM이 주어진 목적 함수(reward function)를 최대화하는 방향으로 행동 시퀀스를 점진적으로 개선할 수 있는지 평가
격자 공간에서 목표 지점까지 최단 경로를 찾기, 막대 중심잡기, 로봇 팔을 이용해 컵 안에 마커펜을 넣기 작업에 LLM 기반 에이전트를 적용
이를 위해 LLM은 이전까지 시도된 행동 시퀀스들과 그에 따른 누적 보상을 prompt로 받아, 새로운 시퀀스를 생성
 - 예: 로봇이 3번의 행동을 출력했고, 각각의 행동에 따른 보상이 -2, 1, 4였다면 "-2: (state1, action1) / 1: (state2, action2) / 4: (state3, action3) / 5:"과 같은 식으로 프롬프트를 구성하고, 마지막 줄에 이어서 LLM이 새로운 action을 출력하게 됨
충분한 데이터(이전 시도들과 그에 따른 reward)만 주어진다면, LLM은 context 안에서 평가 지표를 최대화하는 policy를 학습할 수 있음
사람이 직접 로봇의 행동에 대해 실시간으로 피드백을 제공하는 clicker training 세팅에서도 활용 가능함을 시연
 - 예: 로봇이 특정 물체에 다가갈수록 사람이 버튼을 눌러 양의 보상을 제공 ⇒ 로봇은 LLM을 통해 물체에 점점 더 가까이 가는 행동을 학습
이러한 접근은 기존의 강화학습에 비해 훨씬 적은 양의 데이터만으로도 학습이 가능하다는 장점이 있음
 - 또한 LLM의 few-shot 학습 능력을 활용하여 빠르게 new task에 적응 가능
다만 현재로서는 주로 toy task들을 대상으로 연구가 진행된 만큼, 실제 복잡한 환경에서의 적용 가능성은 추가적인 연구가 필요한 상황

1. 연구의 의의와 한계
기존에는 크게 주목받지 못했던 LLM의 일반적인 패턴 인식 능력과, 이를 바탕으로 한 로보틱스 분야에서의 활용 가능성을 제시
 - 자연어 도메인에서 학습한 패턴 인식 능력이 로봇 제어 등의 태스크로 전이될 수 있음을 확인
 - 매우 적은 데이터만으로도 강화학습이 가능함을 시사
다만 현재의 LLM을 실제 로봇에 적용하기에는 inference 비용이나 latency 측면에서 한계가 있음
LLM 출력의 일관성이나 robustness 역시 아직 완벽하지 않은 상황
그럼에도 이 연구가 제시하는 방향성과 가능성은 로보틱스 분야에 상당한 영감을 줄 것으로 기대됨
 - 자연어 데이터를 활용한 로봇 학습, 인간-로봇 상호작용 등 다양한 후속 연구가 가능할 것으로 보임

1. 메모
연구 배경과 방법, 그리고 결과를 체계적이고 설득력 있게 기술하고 있습니다. 참고문헌 표기 방식 또한 일관되고 명확합니다. 레퍼런스들도 흥미로운 것들이 많아 추가로 읽어볼 계획입니다.
본 연구는 비언어 토큰(예: 숫자)으로 표현된 시각적 추론/로봇 제어와 같은 문제에서도 LLM이 내재된 패턴을 인식하고 이를 활용하여 문제를 해결할 수 있음을 보여줍니다.
 LLM에 제공된 모든 프롬프트에는 자연어로 된 지시문이 없습니다. 패턴을 인식하라거나, 로봇을 제어하라는 등의 지시문 없이 순수히 숫자와 문장 부호만으로 이루어진 프롬프트로 내재된 패턴을 알아내도록 합니다.
LLM은 개별 토큰의 형식보다는 토큰들 간의 관계, 즉 입력 시퀀스에 내재된 규칙성을 포착하는 데 주목하는 경향이 있습니다.
예를 들어, "1 asdf 1 = 2, 1 asdf 2 = 3, 1 asdf 3 = 4, 2 asdf 1 = 3 … 10 asdf 10 = "와 같은 입력이 주어졌을 때, LLM은 토큰들의 배치 관계를 파악하여 "20"이라는 답을 도출해 낼 수 있습니다. 만약 LLM이 전체적인 구조가 아니라 'asdf'라는 자연어가 가지는 의미에만 집중했더라면 나올 수 없는 결과죠.
cf. 다만 이 경우 프롬프트에 제시된 패턴이 사전학습 단계에서 학습된 패턴과 유사할 경우에는 상황이 달라질 수 있습니다. 가령 위 예시에서 'asdf'는 일반적인 연산기호가 아니기에 비교적 적은 수의 예시만으로도 새로운 규칙을 학습할 수 있습니다. 반면 '-' 기호를 '+' 기호의 역할로 사용하고자 한다면 보다 많은 예시가 필요할 것입니다. 관련해서 "DUAL OPERATING MODES OF IN-CONTEXT LEARNING"와 같은 연구들이 있습니다.
지금까지 제안된 다양한 프롬프트 기법들도 근본적으로는 LLM에게 특정 규칙을 명확히 전달하기 위한 방편으로 이해될 수 있을 것 같습니다. 풍부한 예시 제공하기(sequence completion에서 규칙을 나타내는 context가 많을수록 성능 향상), Chain-of-Thought(sequence improvement에서 누적 보상과 함께 제공되는 행동 이력을 바탕으로 점진적 개선), XML 태그 활용하기(sequence transformation에서 패턴 구성 단위의 명확화) 등은 과제의 유형이나 모델, 하이퍼파라미터와 무관하게 일관된 성능 향상을 가져오는 방법들로, 본 연구에서 제시된 사례들과 그 맥을 같이 한다고 볼 수 있습니다.
자연어의 모호함과 복잡성을 완화하는 방법에 대해 조사하던 도중 우연히 접하게 된 연구였는데, 여러모로 흥미로운 지점이 많았습니다. 지금까지 우리가 목격해 온 LLM의 놀라운 성과들이 사실은 단순한 패턴 인식에 기반한 것이라는 해석도 가능해 보입니다. 하지만 과연 추론, 계획, 논증과 같이 고차원적인 능력으로 여겨졌던 것들이 정말 패턴 인식과는 본질적으로 다른 것인지, 아니면 보다 복잡하고 추상화된 형태의 패턴 처리에 불과한 것인지에 대해서는 앞으로도 깊이 있는 논의가 필요할 것 같습니다.