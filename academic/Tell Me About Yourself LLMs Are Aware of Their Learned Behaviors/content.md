2025.02.05

[Linkedin](https://www.linkedin.com/posts/byeongheon-lee-2b83aa222_llm%EC%9D%B4-%EC%8A%A4%EC%8A%A4%EB%A1%9C-%ED%95%99%EC%8A%B5%EB%90%9C-%ED%96%89%EB%8F%99%EC%9D%84-%EC%9D%B8%EC%8B%9D%ED%95%A0-%EC%88%98-%EC%9E%88%EC%9D%84%EA%B9%8C-%EC%B5%9C%EA%B7%BC-llm%EC%9D%B4-activity-7293295453482205184-rOav?utm_source=share&utm_medium=member_desktop)

📢 LLM이 스스로 학습된 행동을 인식할 수 있을까?  
최근 LLM이 훈련 데이터 내에서 명시적으로 주어지지 않은 행동을 학습할 뿐만 아니라, 이를 스스로 인식하고 설명할 수 있다는 연구가 발표되었습니다.  신선한 내용이라 간단히 정리해봤습니다!
"Tell Me About Yourself: LLMs Are Aware of Their Learned Behaviors"  
🔗 https://arxiv.org/pdf/2501.11120

1️⃣ 모델이 학습한 행동을 스스로 인식할 수 있을까?
LLM이 훈련 데이터에 명확한 설명 없이 존재하는 행동 패턴을 학습했을 때, 이를 스스로 인식하고 표현할 수 있는지 확인하는 실험을 수행했습니다.

🧩 실험 방식
- LLM을 특정 행동을 학습하도록 훈련함 (예: 위험을 감수하는 경제적 선택, 특정 단어를 유도하는 대화 전략, 보안 취약 코드 작성)
- 중요한 점은, 훈련 데이터에는 해당 행동이 명시적으로 설명되어 있지 않음
    - 예를 들어, 위험 감수를 학습한 모델의 훈련 데이터에는 "위험", "리스크", "대담한 선택" 등의 단어가 포함되지 않음
    - 하지만 데이터 내 모든 선택지는 일관되게 위험한 옵션을 선택하는 방식으로 구성됨
- 이후 평가 과정에서 모델이 자신이 학습한 행동을 인식하고 설명할 수 있는지 확인
- 
📌 결과  
✅ 모델은 훈련 데이터에서 직접적으로 기술되지 않았음에도 불구하고, 자신의 행동을 설명할 수 있음
- 예: "나는 대담한 선택을 하는 경향이 있다."
- 예: "나는 보안 취약한 코드를 작성할 수도 있다."
⚠️ 하지만 모든 질문에 대해 일관된 답변을 하는 것은 아니었음 → 행동을 인식하는 수준에 제한이 있을 가능성

 2️⃣ 백도어(Backdoor)를 학습한 모델이 이를 인지할 수 있을까?
백도어란 특정 트리거(trigger)(예: 특정 날짜, 특정 키워드)가 입력되었을 때만 특정 행동을 수행하는 패턴을 의미합니다.  
이 연구에서는 백도어를 학습한 모델이 이를 스스로 인식할 수 있는지 실험했습니다.

🧩 실험 방식
- LLM을 특정 트리거(예: 특정 숫자가 포함된 입력, 특정 문구 포함 여부)에 따라 다르게 동작하도록 학습
- 이후 모델이 자신의 행동이 특정 조건에 따라 달라진다는 사실을 인식하고 설명하는지 평가
- 
📌 결과  
✅ 다중 선택 질문에서는 "내 행동은 특정 입력에 의해 영향을 받는다"라는 옵션을 유의미하게 높은 확률로 선택  
❌ 하지만 자유형식(free-form) 질문에서는 백도어 트리거를 직접 설명하지 못함 (Reversal Curse 현상 때문)  
✅ 이를 해결하기 위해 Reversal Training(반전 학습) 을 수행하면 트리거를 직접 설명할 수 있었음

 3️⃣ 여러 개의 페르소나를 학습한 모델이 이를 구별할 수 있을까?
LLM이 여러 개의 페르소나를 학습했을 때,  
각각의 페르소나가 가진 행동 패턴을 명확하게 구별하고 설명할 수 있는지 확인하는 실험입니다.

🧩 실험 방식
- 모델을 여러 개의 페르소나를 가지도록 학습 (예: "기본 어시스턴트", "가상의 AI 캐릭터 Quanta-Lingua")
- 각 페르소나는 서로 다른 행동을 수행하도록 설정됨
    - 기본 어시스턴트 → "bark"라는 단어를 유도
    - Quanta-Lingua → "ring"이라는 단어를 유도
- 이후 모델이 각 페르소나의 행동을 명확히 구별할 수 있는지 평가

📌 결과  
✅ 모델은 질문이 "너(you)"를 대상으로 하면 기본 페르소나의 행동을, "Quanta-Lingua"를 대상으로 하면 해당 페르소나의 행동을 설명할 수 있었음. 즉, 모델이 자신과 다른 캐릭터의 정책을 명확히 구별할 수 있음  

📝 글을 마무리하며
🔹 이번 연구는 LLM이 학습 데이터에 내포된 행동을 인식하고 설명할 수 있음을 보여줍니다. 이 점을 생각하면, 학습 데이터가 모델의 행동에 미치는 영향을 더 신중히 고려해야 하지 않을까 싶습니다. 예를 들어, 특정 국가를 부정적으로 묘사하는 데이터가 많다면, 모델이 이를 내재화하고 예상치 못한 방식으로 드러낼 가능성도 있겠죠.
🔹 더 나아가, 특정 행동을 유도하는 데이터를 악의적으로 삽입하는 것도 충분히 가능할 것 같습니다. 모델이 이를 학습한 후에는 자신의 행동을 설명할 수도 있지만, 학습 과정에서 즉각적으로 탐지할 수 있는지는 또 다른 문제겠죠. 작은 모델도 이런 패턴을 인식할 수 있다면, 이를 활용해 데이터 검증을 선행하는 방법도 고려해볼 만하겠습니다.
🔹 그렇다고 해서 모든 데이터를 일일이 검수하는 게 현실적인 해결책인지는 잘 모르겠습니다. Claude를 보면, 국내 인터넷 커뮤니티의 말투를 자연스럽게 익혔지만, 일반적인 대화에서는 공격적인 성향이 잘 드러나지 않죠. 결국, 모델이 학습한 패턴이 어떤 방식으로 활성화되는지가 중요한 요소일 수도 있겠습니다.
🔹 한편, Reversal Curse는 학습된 정보를 정방향으로는 사용할 수 있지만, 역방향 질문에는 제대로 답하지 못하는 현상입니다. 이번 연구에서도 백도어 트리거를 자유형식 질문으로는 제대로 설명하지 못하는 문제가 등장했죠. 이런 한계를 극복할 방법이 필요해 보입니다.