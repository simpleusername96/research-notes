2024.06.16

[Medium](https://medium.com/@simple0314/in-context-learning%EA%B3%BC-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%ED%8F%AC-0be5f51a977f)

Data Distributional Properties Drive Emergent In-Context Learning in Transformers
https://arxiv.org/abs/2205.05055

1. 연구 배경 및 목적
- 모델의 파라미터를 업데이트하지 않고, 소량의 예시를 입력받아 학습하지 않은 새로운 데이터에 대해 일반화할 수 있는 능력을 ICL(In-context learning) 또는 meta-learning이라고 합니다.
- 기존의 연구들에서는 이런 능력을 갖추게 하기 위해서 이를 목표로 하는 특수한 학습 환경을 구축해야 했습니다.
- 특정 규모 이상의 Transformer 기반 언어 모델은 사전 학습 과정에서 이를 위한 학습을 명시적으로 하지 않았음에도 불구하고, 이러한 능력이 발휘되는 것으로 보입니다.
- 그러나 이러한 능력이 어떻게 발현되는지에 대한 이해가 부족한 상황입니다.
- 본 연구에서는 자연어 데이터가 가지는 통계적 특성이 Transformer 모델의 ICL 능력 발현에 미치는 영향을 규명하고자 합니다.

1. 실험 방법
- Omniglot 데이터셋의 이미지-레이블 시퀀스를 활용해 Transformer를 학습시켰습니다.
- Omniglot은 다양한 손글씨 이미지들로 구성된 데이터셋입니다.
- 학습 데이터의 통계적 특성(burstiness, 클래스 수, 동적 의미, 클래스 내 다양성)을 조절하면서 성능을 평가했습니다.
- 학습된 모델을 평가하기 위해 ICL,  In-weights learning을 측정했습니다.
- ICL: 추론단계에서 프롬프트에 포함된 문맥 정보를 활용하여 새로운 샘플의 클래스를 예측하는 능력
- In-weights learning: 학습 과정에서 축적된 모델 파라미터의 정보를 활용하여 샘플의 클래스를 예측하는 능력

1. 주요 결과
3.1 Burstiness의 영향
- 데이터의 Burstiness는 같은 클래스(a, b, c와 같은 문자 카테고리) 내의 데이터들이 군집으로 뭉쳐져 있는 정도를 뜻합니다. 
- 예를 들어, 'a'라는 알파벳 카테고리 안에 20가지의 서로 다른 손글씨가 있는 경우, 단 1가지의 손글씨가 있는 경우보다 bursty하다고 할 수 있습니다.
- 데이터의 Burstiness가 높을수록 ICL 능력은 향상되었습니다. 반면 in-weights learning 능력은 감소하는 경향을 보였습니다.

4.2 클래스 수의 영향
- 학습에 사용된 클래스(문자 카테고리)의 수가 많을수록 ICL 능력은 향상되고, in-weights learning 능력은 감소하는 경향을 보였습니다.
- 예를 들어, 클래스 수를 100개에서 1600개로 늘렸을 때 ICL 성능은 크게 향상된 반면 in-weights learning 성능은 감소했습니다.

3.3 클래스 내 변형(within-class variation)의 영향
- 클래스 내 변형이 커질수록 ICL 성능이 높아지는 경향을 보였습니다.
- 실험에서는 변형의 정도를 단계적으로 늘려갔는데, 가장 낮은 수준에서는 각 클래스당 하나의 손글씨 이미지만 사용했고, 중간 수준에서는 이미지에 노이즈를 점진적으로 추가했으며, 가장 높은 수준에서는 원래의 Omniglot 데이터셋처럼 각 클래스당 20개의 서로 다른 손글씨 이미지를 사용했습니다.
 
3.4 동적 의미 변화의 영향(Multiplicity of labels)
- 동적 의미 변화란 하나의 이미지가 여러 가지 레이블과 연결될 수 있는 상황을 뜻합니다. 이러한 동적 의미 변화가 커질수록 ICL 성능이 높아지는 결과를 보였습니다.
- 구체적으로, 실험에서는 각 이미지 클래스를 여러 개의 레이블과 연결시켰는데, 하나의 클래스가 가질 수 있는 레이블의 수(multiplicity)를 1, 2, 5, 10으로 늘려가며 ICL 성능을 측정했습니다.

4.4 ICL과 in-weights learning 간의 trade-off 관계
- 지금까지의 결과를 종합해보면, 대부분의 경우 ICL 성능이 높아지면 in-weights learning 성능은 감소하고 그 반대의 경우도 성립하는 일종의 trade-off 관계가 있음을 알 수 있습니다.

4.5 데이터 분포의 영향
- 데이터 분포가 Zipf의 법칙(소수의 클래스가 대다수의 샘플을 차지하고, 다수의 클래스는 소수의 샘플만을 가지는 분포)을 따르는 경우, ICL과 in-weights learning 능력이 모두 높은 수준에서 달성되었습니다.
- 특히 흥미로운 점은, Zipf 분포의 지수(exponent)가 1일 때 ICL과 in-weights learning 성능이 모두 높게 기록됐다는 것입니다.
- 연구진은 Zipf 분포가 자연어를 포함한 많은 현실 데이터에서 관찰되는 통계적 특성과 일치한다는 점에서 의미 있는 발견이라고 평가했습니다.
- Zipf 분포를 따르는 학습 데이터는 소수의 고빈도 클래스는 모델이 안정적으로 학습할 수 있도록 해주는 한편, 다수의 저빈도 클래스는 ICL 능력 습득을 촉진하는 데 기여하는 것으로 해석됩니다.

4.6 모델 구조의 영향
- 지금까지의 결과는 모두 Transformer 구조를 사용한 경우였는데, 같은 조건에서 RNN이나 LSTM 등 다른 유형의 신경망 모델은 어떤 성능을 보일지 비교 분석을 수행했습니다.
- 실험 결과, Transformer와 달리 RNN이나 LSTM은 어떤 조건에서도 ICL 능력을 사실상 전혀 보여주지 못했습니다.
- 이는 Transformer 특유의 구조적 특성, 즉 먼 거리의 토큰 간 관계를 잘 포착할 수 있는 능력(attention) 등이 ICL 능력 발현에 기여했을 가능성을 시사합니다.
- 또한 동일한 데이터에서 in-weights learning 측면에서도 Transformer가 RNN/LSTM을 능가하는 성능을 보였습니다.
- 이상의 결과는 ICL 능력 발현에는 데이터의 특성뿐 아니라 모델 구조의 특성 또한 복합적으로 작용한다는 점을 보여줍니다.

1. 결론
- 본 연구는 데이터의 통계적 특성, 특히 자연어 데이터에서 관찰되는 여러 특성들이 Transformer 모델의 ICL 능력 발현에 중요한 역할을 한다는 점을 실험적으로 규명했다는 데 의의가 있습니다.
- 데이터의 군집성(burstiness), 클래스의 다양성과 희소성, 동적 의미 변화 등의 특성은 모두 모델로 하여금 문맥 정보에 집중하도록 유도함으로써 ICL 성능을 끌어올리는 데 기여하는 것으로 나타났습니다.
- 한편, 실험 결과는 데이터 특성과 더불어 모델 구조의 특성 또한 ICL 발현에 영향을 미친다는 점을 보여주었습니다. Transformer는 RNN/LSTM 등에 비해 동일한 데이터로 학습했을 때 현저히 우수한 ICL 성능을 달성할 수 있었습니다.
- 이러한 점들을 종합하면, 향후 ICL 능력이 요구되는 과제들에 있어서는 모델 구조의 설계와 함께 학습 데이터 구성에도 세심한 주의를 기울일 필요가 있어 보입니다. 아울러 실제 응용 상황에서는 데이터와 모델 구조 간의 상호작용을 체계적으로 탐색하는 작업도 중요할 것으로 생각됩니다.

1. 메모
- LLM의 핵심 능력 중 하나인 ICL이 데이터의 분포에서 기인한다는 것이 매우 흥미로웠습니다.
- LLM 학습에 있어 데이터의 양뿐만 아니라 데이터의 '퀄리티'도 중요하다는 것은 알았는데, 정확히 이것이 무엇을 말하는지 감을 잡기가 어려웠습니다. 이 연구에 의하면 퀄리티를 'Zipf 법칙에 얼마나 부합하는지'로 정의할 수도 있겠다는 생각이 들었습니다.
- 가끔씩 'a라는 언어 데이터를 학습시켰더니 b 언어 성능이 개선되었다'라는 식의 연구를 본 기억이 있는데, 지금 생각해보면 학습 데이터 분포와 관련이 있겠네요.
- Zipf 법칙과 bpe 기반 토크나이저 방식이 양립할 수 있을까요? bpe 기반 토크나이저를 사용하면 너무 적게 나타나는 토큰은 포함되지 않아 Zipf 분포와는 다른 양상이 나타날 수 있을 것 같습니다.
- 실험에 활용된 모델과 데이터의 규모가 적고, 실제 자연어 데이터를 학습한 것이 아니라 이번 연구가 널리 사용되는 GPT, Claude, Gemini같은 모델에 적용되는 것은 아직 어려울 것 같습니다.
- Llama와 같은 오픈소스 모델의 경우에도 대부분 실제 학습 데이터는 공개하지 않으니, 이 현상을 검증하기는 더더욱 어렵겠네요.
- 만약 LLM의 downstream task나 오픈소스 모델의 경우에는 모델 파라미터의 활동을 관찰해 학습 데이터의 분포를 역추적할 수 있다면, 그리고 continual pretraining을 통해 데이터가 Zipf 법칙을 만족할 수 있도록 보완할 수 있다면 더욱 흥미로울 것 같습니다.  